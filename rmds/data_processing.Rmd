---
title: "smartchem_raw_to_db"
author: "Keith Birchfield"
date: "February 21, 2019"
output: 
  html_document:
    toc: TRUE
    df_print: paged
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
```

## Description

This Rmd is a record of the data processing for raw data files output from SmartChem 200 software. The goal is to prepare data for import into the pnw_lakes_data database. Preparation includes evaluation of quality control metrics and notes about any changes to the data set. 

### Samples in Data Set

This data set includes the following samples, all from Lacamas Lake:

  * 2018 DW profile samples
  * 2018 Inlet and Outlet samples
  
## Load required packages and functions

```{r}
library(tidyverse)
library(lubridate)
library(readxl)
library(cowplot)
library(plotly)
library(here)
source(here("functions", "smartchem_rawprocessor.R"))
source(here("functions", "sc_qc_multiplot_fun.R"))
source(here("functions", "sc_cal_curve_plot.R"))
source(here("functions", "sc_controls_plot.R"))
source(here("functions", "sc_absdups_plot.R"))
source(here("functions", "sc_no3coileffic_plot.R"))
```

## Import data

Make a list of file names in the raw_data folder

```{r}
filenames_raw <-
  list.files(here("raw_data"), pattern = "*\\.XLS", ignore.case = T, full.names = F)
filenames_raw
```

Specify the run dates for each file in filenames.orig and create a dataframe of filenames and their associated rundates
```{r}
run_dates_df <- as_tibble(list(filenames = filenames_raw, 
                               run_dates  = date(c("2019-02-12", "2019-02-12", "2019-02-13", "2019-02-14", "2019-02-14"))))
run_dates_df
```

## WNHR - Ammonia analysis data processing

### Import and Process excel workbook

```{r}
nh3_run <- smartchem_rawprocessor(filename = filenames_raw[1])
nh3_run
```

Check the method to make sure it is an ammonia method (WNHR or WNHA)

```{r}
nh3_run$method
```


### Quality Control Checks

1. Calibration curve

```{r}
sc_cal_curve_plot(nh3_run)
```

2. Check Standards and Controls

```{r}
sc_controls_plot(nh3_run)
```


```{r}
#nh3_controls_plot <- 
# nh3_run$controls %>% mutate(Concentration = ifelse(SampleID == "BLNK" & Concentration > 0.25, NA, Concentration)) %>% 
#   ggplot(aes(RunTime, Concentration, color = SampleID)) +
#   geom_point() +
#   geom_line() +
#   geom_smooth(method = "lm", se = F) +
#   ggtitle(label = paste(nh3_run$method, "- Controls", nh3_run$run_date)) + 
#   xlab("Runtime") +
#   ylab("Concentration") +
#   #theme(legend.position = "top") +
#   geom_hline(yintercept = unique(nh3_run$controls$Nominal), linetype = 2)
# ggplotly(nh3_controls_plot) %>% 
#   layout(legend = list(orientation = "h", y = 1.05))
```



```{r}
nh3_midcheck_pctrec <- 
  nh3_run$controls %>% 
  filter(SampleID == "CCA1") %>% 
  ggplot(aes(RunTime, Recovery_PRD)) +
  geom_point() + 
  geom_line() +
  geom_hline(yintercept = c(100, 90, 110), linetype = c(1,2,2), color = "green") +
  labs(title = paste(nh3_run$method, "- Midrange Check % Recovery ", nh3_run$run_date))
ggplotly(nh3_midcheck_pctrec)

```


The checks and blanks were good on this run. Only one mid-range check fell outside of the 10% error threshold (runtime = 13:32), but it was only slightly below the threshold at 89.3% recovery. This is acceptable. 


3. Duplicates analysis

  a. Absolute difference over time
  
```{r}
sc_absdups_plot(nh3_run)
```


All three together for comparison

```{r, fig.height=10, fig.width=10}
sc_qc_multiplot_fun(nh3_run)
```

```{r}
hist(nh3_run$dups$abs_diff_conc)
```


```{r}
nh3_run$dups %>% 
  summarise(avg_abs_diff = mean(abs_diff_conc),
            sd_abs_diff = sd(abs_diff_conc), 
            n_abs_diff = n(),
            cv = 100 * sd_abs_diff/avg_abs_diff)
```




### Data quality and corrections assessment


Assessment:


Mid-range check standards and blanks were good on the whole for ammonia. Dups were good for most of the run with an average absolute diff of less than 0.009 ppm, which is 1.7% of the mid-range check standard. The highest differences in dups came later in the run and correspond to higher concentrations (see figure below). It appears that error increases with concentration, but there aren't enough dups at higher concentrations in this run to make any conclusions about this trend. 

For this run, I'll accept the results without any corrections.   

```{r}
nh3_run$dups %>% ggplot(aes(Concentration, abs_diff_conc)) + geom_point()
```

### Out of range

Check results for samples that were out of range.

```{r}
nh3_run$result %>% 
  filter(Concentration > 2)
```
Two samples were out of the range of the calibration curve. For some unknown reason, these were not automatically rerun even though the method parameters are set up to rerun samples greater than 2ppm (I checked this). These should both be rerun, particularly the 2018-08-16 sample at almost 5ppm. I'll flag both of these as reruns for being outside of the calibration range.

Corrections and reruns:
* No corrections required
* Flag two samples for reruns

Add metadata and save to merge with results of other analytes.

```{r}
nh3_results_final <- 
nh3_run$result %>% 
  mutate(method = nh3_run$method,
         analyte = "nh3",
         qc_flag = case_when(SampleID == "2404_Lac_IN_2018-08-16 15:30_" | 
                               SampleID == "2544_Lac_DW_2018-10-30 11:15_16.4" ~ "rerun: out of range"))

nh3_results_final
```

## SMPL - Phosphate 

### Import and Process excel workbook

```{r}
po4_run <- smartchem_rawprocessor(filename = filenames_raw[2])
po4_run
```

Check the method to make sure it is a phosphate method (SMPL)

```{r}
po4_run$method
```

### Quality Control Checks

1. Calibration curve

```{r}
sc_cal_curve_plot(po4_run)
```

2. Check Standards and Controls

```{r}
sc_controls_plot(po4_run)
```


```{r}
po4_midcheck_pctrec <-
  po4_run$controls %>%
  filter(SampleID == "CCV1") %>%
  ggplot(aes(RunTime, Recovery_PRD)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = c(100, 90, 110), linetype = c(1,2,2), color = "green") +
  labs(title = paste(po4_run$method, "- Midrange Check % Recovery ", po4_run$run_date))
ggplotly(po4_midcheck_pctrec)

```


3. Duplicates analysis

  a. Absolute difference over time
  
```{r}
sc_absdups_plot(po4_run)
```


All three together for comparison

```{r, fig.height=10, fig.width=10}
sc_qc_multiplot_fun(po4_run)
```

```{r}
hist(po4_run$dups$abs_diff_conc)
```


```{r}
po4_run$dups %>%
summarise(avg_abs_diff = mean(abs_diff_conc),
          sd_abs_diff = sd(abs_diff_conc),
          n_abs_diff = n(),
          cv = 100 * sd_abs_diff/avg_abs_diff)
```

```{r}
po4_run$dups %>% ggplot(aes(Concentration, abs_diff_conc)) + geom_point()
```



### Data quality and corrections assessment

As seems to be typical for phosphate, the controls in this run were not as accurate as for other methods. Both the mid-range checks and the blanks were consistently low relative to their expected values by 0.005 to 0.01 ppm, which would seem to point to the calibration curve being slightly off. Given that most of the dups had a concentration around 0ppm or below, it's likely that the concentrations were near or below the detection limit for this method. I'll proceed without any corrections. 

### Out of range

Check results for samples that were out of range.

```{r}
po4_run$result %>% 
  filter(Concentration > 0.1)
```
One sample was out of the range of the calibration curve. For some unknown reason, this was not automatically rerun even though the method parameters are set up to rerun samples greater than 0.1 ppm (I checked this). This should be rerun, particularly given it is more than 6x the concentration of the calibration standard. I'll flag as rerun for being outside of the calibration range.

Corrections and reruns:
* No corrections required
* Flag one sample for rerun

Add metadata and save to merge with results of other analytes.

```{r}
po4_results_final <-
po4_run$result %>%
  mutate(method = po4_run$method,
         analyte = "po4",
         qc_flag = case_when(SampleID == "2404_Lac_IN_2018-08-16 15:30_" ~ "rerun: out of range"))

po4_results_final
```




## BNO2 - Nitrite

### Import and Process excel workbook

```{r}
no2_run <- smartchem_rawprocessor(filename = filenames_raw[4])
no2_run
```

Check the method to make sure it is a nitrite method (BNO2)

```{r}
no2_run$method
```


### Quality Control Checks

1. Calibration curve

```{r}
sc_cal_curve_plot(no2_run)
```

2. Check Standards and Controls

```{r}
sc_controls_plot(no2_run)
```


```{r}
no2_midcheck_pctrec <- 
  no2_run$controls %>% 
  filter(SampleID == "CCN2") %>% 
  ggplot(aes(RunTime, Recovery_PRD)) +
  geom_point() + 
  geom_line() +
  geom_hline(yintercept = c(100, 90, 110), linetype = c(1,2,2), color = "green") +
  labs(title = paste(no2_run$method, "- Midrange Check % Recovery ", no2_run$run_date))
ggplotly(no2_midcheck_pctrec)

```


3. Duplicates analysis

  a. Absolute difference over time
  
```{r}
sc_absdups_plot(no2_run)
```


All three together for comparison

```{r, fig.height=10, fig.width=10}
sc_qc_multiplot_fun(no2_run)
```
```{r}
hist(no2_run$dups$abs_diff_conc)
```


```{r}
no2_run$dups %>% 
  summarise(avg_abs_diff = mean(abs_diff_conc),
            sd_abs_diff = sd(abs_diff_conc), 
            n_abs_diff = n(),
            cv = 100 * sd_abs_diff/avg_abs_diff)
```

### Data quality and corrections assessment

Overall, controls were good for this run. The spike in the blank mid-run was the result of the sample cup running empty. No corrections required.  

### Out of range

Check results for samples that were out of range.

```{r}
no2_run$result %>% 
  filter(Concentration > 0.5)
```

No samples were out of range.

Correct a typo in SampleID for sample at position 6. Then add metadata and save to merge with results of other analytes.
```{r}
no2_run$result$SampleID[6] <- nh3_run$result$SampleID[6] 

no2_results_final <- 
no2_run$result %>% 
  mutate(method = no2_run$method,
         analyte = "no2")

no2_results_final

```




## BNO3 - Nitrate

### Import and Process excel workbook

```{r}
no3_run <- smartchem_rawprocessor(filename = filenames_raw[3])
no3_run
```

Check the method to make sure it is a nitrate method (BNO3)

```{r}
no3_run$method
```


### Quality Control Checks

1. Calibration curve

```{r}
sc_cal_curve_plot(no3_run)
```



2. Check Standards and Controls

```{r}
sc_controls_plot(no3_run)
```


```{r}
no3_midcheck_pctrec <- 
  no3_run$controls %>% 
  filter(SampleID == "CCN3") %>% 
  ggplot(aes(RunTime, Recovery_PRD)) +
  geom_point() + 
  geom_line() +
  geom_hline(yintercept = c(100, 90, 110), linetype = c(1,2,2), color = "green") +
  labs(title = paste(no3_run$method, "- Midrange Check % Recovery ", no3_run$run_date))
ggplotly(no3_midcheck_pctrec)

```


3. Duplicates analysis

  a. Absolute difference over time
  
```{r}
sc_absdups_plot(no3_run)
```


All three together for comparison

```{r, fig.height=10, fig.width=10}
sc_qc_multiplot_fun(no3_run)
```

```{r}
hist(no3_run$dups$abs_diff_conc)
```


```{r}
no3_run$dups %>% 
  summarise(avg_abs_diff = mean(abs_diff_conc),
            sd_abs_diff = sd(abs_diff_conc), 
            n_abs_diff = n(),
            cv = 100 * sd_abs_diff/avg_abs_diff)
```



Nitrate module coil efficiency

```{r}
sc_no3coileffic_plot(no3_run)
```

Mean coil efficiency (blue dotted line) = `r mean(no3_run$controls$coil_effic, na.rm = T)`
This is inaccurate. I made a new mid-range standard (1ppm NO3) after the run because the mid-range NO3 check was consistently low. Comparing the two, the new 1ppm NO3 was slightly higher than the 1ppm NO3 used in the run. Absorption values were as follows: 

2ppm NO3 standard for calibration = 0.728
1ppm NO3 mid-range used in run = 0.335
1ppm NO3 mid-range made fresh after run = 0.360
1ppm NO2 used in run = 0.410

Using the new 1ppm NO3 compared to the 1ppm NO2, the coil efficiency = 100 * 0.360/0.410 = 88%


### Data quality and corrections assessment

Overall, controls were good for this run. 

### Out of range

Check results for samples that were out of range.

```{r}
no3_run$result %>% 
  filter(Concentration > 2)
```

Three samples were out of range. All three were automatically rerun. I'll remove the first sets and keep the reruns.

Add metadata and save to merge with results of other analytes. 
```{r}
no3_results_final <- 
no3_run$result %>% 
  filter(Abs <= 0.93) %>% 
  mutate(method = no3_run$method,
         analyte = "no3")

no3_results_final

```

## Merge all, filter out the check samples (position = 1), add metadata, and export

```{r}
filename_dbimport <- paste0("sc_20190221_dbimport_", format(Sys.time(), format = "%Y%m%d%H%M"), ".csv")
filename_dbimport

merged_results <- 
bind_rows(list(nh3_results_final, 
               po4_results_final, 
               no2_results_final, 
               no3_results_final)) %>% 
  filter(Position > 1) %>% 
  separate(SampleID, into = c("ws_info_id", "reservoir", "site", "datetime", "depth_nominal"), sep = "_", remove = FALSE) %>% 
  mutate(reservoir = case_when(reservoir == "Lac" ~ "Lacamas"), 
         date_col = date(datetime),
         filename = filename_dbimport) %>% 
  rename(sample_id = SampleID,
         sample_type = SampleType,
         run_time = RunTime) 

merged_results

merged_results %>% 
  write_excel_csv(path = here("produced_data", filename_dbimport), 
                  na = "")
```



